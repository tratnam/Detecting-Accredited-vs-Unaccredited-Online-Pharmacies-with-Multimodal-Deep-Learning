{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9cab500-489a-4f20-832d-0a67b551e9f5",
   "metadata": {},
   "source": [
    "## Mulitmodal Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d36c1ae-5951-42c2-b125-9bffd8092727",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "494c3500-3d44-423c-b2f8-465a2d6614b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "import os \n",
    "import requests\n",
    "import urllib\n",
    "import ssl\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import keras\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from sklearn.metrics import confusion_matrix,f1_score,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import itertools\n",
    "from keras.models import load_model\n",
    "from sklearn.utils import shuffle\n",
    "from transformers import *\n",
    "from transformers import BertTokenizer, TFBertModel, BertConfig\n",
    "import tensorflow_text as text\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d868df-725b-4938-8c1f-aeacafa7010c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import splitfolders\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0210a4-317e-49e0-8b2e-21a9036d4ce9",
   "metadata": {},
   "source": [
    "#### Load Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f6fe71e-dcd3-461f-b28f-a5d2fb3854e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Website</th>\n",
       "      <th>Body</th>\n",
       "      <th>Header</th>\n",
       "      <th>Footer</th>\n",
       "      <th>Image Urls</th>\n",
       "      <th>Accredited</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Valid_phone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://acariahealth.envolvehealth.com</td>\n",
       "      <td>Skip to Main Content Home Contact Insights Sea...</td>\n",
       "      <td>Home Contact Insights Search Search About Over...</td>\n",
       "      <td>Locations Referral Forms Careers Disclaimer HI...</td>\n",
       "      <td>['https://acariahealth.envolvehealth.com/conte...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://alto.com</td>\n",
       "      <td>Shop Alto Essentials to add pharmacy products ...</td>\n",
       "      <td>Shop Alto Essentials to add pharmacy products ...</td>\n",
       "      <td>Our Story Careers Drive for Alto For Providers...</td>\n",
       "      <td>['https://images.prismic.io/alto/176341aa-258d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Website  \\\n",
       "0  https://acariahealth.envolvehealth.com   \n",
       "1                        https://alto.com   \n",
       "\n",
       "                                                Body  \\\n",
       "0  Skip to Main Content Home Contact Insights Sea...   \n",
       "1  Shop Alto Essentials to add pharmacy products ...   \n",
       "\n",
       "                                              Header  \\\n",
       "0  Home Contact Insights Search Search About Over...   \n",
       "1  Shop Alto Essentials to add pharmacy products ...   \n",
       "\n",
       "                                              Footer  \\\n",
       "0  Locations Referral Forms Careers Disclaimer HI...   \n",
       "1  Our Story Careers Drive for Alto For Providers...   \n",
       "\n",
       "                                          Image Urls  Accredited  Zipcode  \\\n",
       "0  ['https://acariahealth.envolvehealth.com/conte...           0        0   \n",
       "1  ['https://images.prismic.io/alto/176341aa-258d...           0        0   \n",
       "\n",
       "   Valid_phone  \n",
       "0            1  \n",
       "1            1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load text data\n",
    "pharm_data = pd.read_csv('pharmacy_dataset_reduced.csv')\n",
    "data = pharm_data.copy()\n",
    "data.head(2)\n",
    "#len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c8119d-0c98-4e40-9a86-452b52f1bbcc",
   "metadata": {},
   "source": [
    "#### Preporcess & Clean Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb20fa97-3b2c-4dd0-8e67-e9f6b63330c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def clean_stopwords_shortwords(w):\n",
    "    stopwords_list=stopwords.words('english')\n",
    "    words = w.split() \n",
    "    clean_words = [word for word in words if (word not in stopwords_list) and len(word) > 2]\n",
    "    return \" \".join(clean_words) \n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w=clean_stopwords_shortwords(w)\n",
    "    w=re.sub(r'@\\w+', '',w)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2800c03-9fc6-47b4-9e52-0a0c41882b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Website</th>\n",
       "      <th>Body</th>\n",
       "      <th>Header</th>\n",
       "      <th>Footer</th>\n",
       "      <th>Image Urls</th>\n",
       "      <th>Accredited</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Valid_phone</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://acariahealth.envolvehealth.com</td>\n",
       "      <td>Skip to Main Content Home Contact Insights Sea...</td>\n",
       "      <td>Home Contact Insights Search Search About Over...</td>\n",
       "      <td>Locations Referral Forms Careers Disclaimer HI...</td>\n",
       "      <td>['https://acariahealth.envolvehealth.com/conte...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Skip to Main Content Home Contact Insights Sea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://alto.com</td>\n",
       "      <td>Shop Alto Essentials to add pharmacy products ...</td>\n",
       "      <td>Shop Alto Essentials to add pharmacy products ...</td>\n",
       "      <td>Our Story Careers Drive for Alto For Providers...</td>\n",
       "      <td>['https://images.prismic.io/alto/176341aa-258d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Shop Alto Essentials to add pharmacy products ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Website  \\\n",
       "0  https://acariahealth.envolvehealth.com   \n",
       "1                        https://alto.com   \n",
       "\n",
       "                                                Body  \\\n",
       "0  Skip to Main Content Home Contact Insights Sea...   \n",
       "1  Shop Alto Essentials to add pharmacy products ...   \n",
       "\n",
       "                                              Header  \\\n",
       "0  Home Contact Insights Search Search About Over...   \n",
       "1  Shop Alto Essentials to add pharmacy products ...   \n",
       "\n",
       "                                              Footer  \\\n",
       "0  Locations Referral Forms Careers Disclaimer HI...   \n",
       "1  Our Story Careers Drive for Alto For Providers...   \n",
       "\n",
       "                                          Image Urls  Accredited  Zipcode  \\\n",
       "0  ['https://acariahealth.envolvehealth.com/conte...           0        0   \n",
       "1  ['https://images.prismic.io/alto/176341aa-258d...           0        0   \n",
       "\n",
       "   Valid_phone                                               text  \n",
       "0            1  Skip to Main Content Home Contact Insights Sea...  \n",
       "1            1  Shop Alto Essentials to add pharmacy products ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine columns into new column containing all text\n",
    "data['text'] = data['Body'].astype(str) + data['Header'].astype(str) + data['Footer'].astype(str)\n",
    "data.head(2)\n",
    "\n",
    "#rename Accredited as 'label'\n",
    "data=data.rename(columns = {'Accredited': 'label'}, inplace = False)\n",
    "data.head(2)\n",
    "\n",
    "#reduce dataset to only the columns we need, 'label' and 'text'\n",
    "data = data.drop(['Website', 'Body', 'Header', 'Footer', 'Image Urls', 'Zipcode', 'Valid_phone'], axis=1)\n",
    "#Sentences contain the entire text data and labels contain all the corresponding labels\n",
    "data.head(3)\n",
    "\n",
    "#drop any missing values\n",
    "data = data.dropna()\n",
    "\n",
    "#reset index\n",
    "data=data.reset_index(drop=True) \n",
    "#shuffle data\n",
    "data = shuffle(data)   \n",
    "data.head(3)\n",
    "\n",
    "#apply the function to clean the text - all lower case, strip spaces and characters \n",
    "data['text']=data['text'].map(preprocess_sentence)    \n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3d6ddf-971e-4258-8078-6bd826fb0c7f",
   "metadata": {},
   "source": [
    "#### Split Data - Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70068a33-0dc4-4821-953b-dc029a57b7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the number of unique classes under 'label'\n",
    "num_classes=len(data.label.unique())\n",
    "num_classes\n",
    "\n",
    "#define y variable\n",
    "y = tf.keras.utils.to_categorical(data[\"label\"].values, num_classes=num_classes)\n",
    "#y\n",
    "\n",
    "#split data into test and train\n",
    "text_x_train, text_x_test, text_y_train, text_y_test = train_test_split(data['text'], y, test_size=0.3)\n",
    "#len(text_x_train), len(text_x_test), len(text_y_train), len(text_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44456895-f798-42b4-9e0a-9d537062d27f",
   "metadata": {},
   "source": [
    "#### BERT Modeling for Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe9ca828-cdb2-422e-9ff3-8a5b3ac1300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load bert with tensorflow hub\n",
    "preprocessor = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder-cmlm/multilingual-preprocess/2\")\n",
    "encoder = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder-cmlm/multilingual-base/1\")\n",
    "\n",
    "#function to get word embeddings\n",
    "def get_embeddings(sentences):\n",
    "  '''return BERT-like embeddings of input text\n",
    "  Args:\n",
    "    - sentences: list of strings\n",
    "  Output:\n",
    "    - BERT-like embeddings: tf.Tensor of shape=(len(sentences), 768)\n",
    "  '''\n",
    "  preprocessed_text = preprocessor(sentences)\n",
    "  return encoder(preprocessed_text)['pooled_output']\n",
    "\n",
    "#test function\n",
    "#get_embeddings([\n",
    "   # \"This is a test para ver el futuro of the model.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e972bb2-bd2e-4aa8-b4db-6e4611ca9e75",
   "metadata": {},
   "source": [
    "#### Create & Train Classification Model\n",
    "- Observe different metrics during training: Precision, Recall, F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ad03d61-cbfe-475d-8e9c-8f4f204e89fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resource: https://towardsdatascience.com/multi-label-text-classification-using-bert-and-tensorflow-d2e88d8f488d#98ee\n",
    "from keras import backend as K\n",
    "\n",
    "#functions to find recall\n",
    "def balanced_recall(y_true, y_pred):\n",
    "    \"\"\"This function calculates the balanced recall metric\n",
    "    recall = TP / (TP + FN)\n",
    "    \"\"\"\n",
    "    recall_by_class = 0\n",
    "    # iterate over each predicted class to get class-specific metric\n",
    "    for i in range(y_pred.shape[1]):\n",
    "        y_pred_class = y_pred[:, i]\n",
    "        y_true_class = y_true[:, i]\n",
    "        true_positives = K.sum(K.round(K.clip(y_true_class * y_pred_class, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true_class, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        recall_by_class = recall_by_class + recall\n",
    "    return recall_by_class / y_pred.shape[1]\n",
    "\n",
    "#functions to find precision\n",
    "def balanced_precision(y_true, y_pred):\n",
    "    \"\"\"This function calculates the balanced precision metric\n",
    "    precision = TP / (TP + FP)\n",
    "    \"\"\"\n",
    "    precision_by_class = 0\n",
    "    # iterate over each predicted class to get class-specific metric\n",
    "    for i in range(y_pred.shape[1]):\n",
    "        y_pred_class = y_pred[:, i]\n",
    "        y_true_class = y_true[:, i]\n",
    "        true_positives = K.sum(K.round(K.clip(y_true_class * y_pred_class, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred_class, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        precision_by_class = precision_by_class + precision\n",
    "    # return average balanced metric for each class\n",
    "    return precision_by_class / y_pred.shape[1]\n",
    "\n",
    "#functions to find f1 score\n",
    "def balanced_f1_score(y_true, y_pred):\n",
    "    \"\"\"This function calculates the F1 score metric\"\"\"\n",
    "    precision = balanced_precision(y_true, y_pred)\n",
    "    recall = balanced_recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8101c740-3177-4b5d-a14f-033587f6e897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "i = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "x = preprocessor(i)\n",
    "x = encoder(x)\n",
    "x = tf.keras.layers.Dropout(0.2, name=\"dropout\")(x['pooled_output'])\n",
    "x = tf.keras.layers.Dense(num_classes, activation='softmax', name=\"output\")(x)\n",
    "\n",
    "bert_model = tf.keras.Model(i, x)\n",
    "\n",
    "# saving and loading the .h5 model\n",
    "# save model\n",
    "#bert_model.save('BERT_Model.h5')\n",
    "#print('Model Saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22131dcb-5e41-420f-9d17-0ce43bd5e691",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define number of epochs\n",
    "n_epochs = 50\n",
    "\n",
    "METRICS = [\n",
    "      tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "      balanced_recall,\n",
    "      balanced_precision,\n",
    "      balanced_f1_score\n",
    "]\n",
    "\n",
    "#EarlyStopping callback to monitor validation loss\n",
    "#if metric doesn't improve for at least 3 epochs (patience = 3)\n",
    "    #training is interrupted and weights from epoch where the validation loss \n",
    "    #showed the best value (i.e. lowest) are restored (restore_best_weights = True)\n",
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", \n",
    "                                                      patience = 3,\n",
    "                                                      restore_best_weights = True)\n",
    "#compile model\n",
    "bert_model.compile(optimizer = \"adam\",\n",
    "              loss = \"categorical_crossentropy\",\n",
    "              metrics = METRICS)\n",
    "#fit model\n",
    "bert_model = bert_model.fit(text_x_train, \n",
    "                      text_y_train, \n",
    "                      epochs = n_epochs,\n",
    "                      validation_data = (text_x_test, text_y_test),\n",
    "                      callbacks = [earlystop_callback], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c83a48c-ca71-4a3a-8fce-8dcec364b002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstruct model\n",
    "#reconstructed_model = keras.models.load_model(\"BERT_Model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd86a1bd-6913-4d81-8322-81d9aa4b3acb",
   "metadata": {},
   "source": [
    "## MobileNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7f3860-1370-4a34-a042-418e33e5cc91",
   "metadata": {},
   "source": [
    "### Load Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b70d0371-1eb6-4e1d-8c82-78718705f94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://acariahealth.envolvehealth.com/content...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://acariahealth.envolvehealth.com/content...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://acariahealth.envolvehealth.com/content...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://acariahealth.envolvehealth.com/content...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://acariahealth.envolvehealth.com/content...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                         image_urls\n",
       "0           0  https://acariahealth.envolvehealth.com/content...\n",
       "1           1  https://acariahealth.envolvehealth.com/content...\n",
       "2           2  https://acariahealth.envolvehealth.com/content...\n",
       "3           3  https://acariahealth.envolvehealth.com/content...\n",
       "4           4  https://acariahealth.envolvehealth.com/content..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df = pd.read_csv('accredited_images.csv')\n",
    "unacc_df = pd.read_csv('unaccredited_images.csv')\n",
    "acc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0e0fd2-21a6-4bb9-8036-8a6ab8b4c832",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0251146-dbab-4442-80d4-3926e8a4499c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haley\\AppData\\Local\\Temp\\ipykernel_20148\\2997277923.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  unacc_df['image_urls'] = unacc_df['image_urls'].str.replace('.md..', '.md.')\n"
     ]
    }
   ],
   "source": [
    "## removes spaces and other inconsistencies in the unaccredited urls \n",
    "unacc_df['image_urls'] = unacc_df['image_urls'].str.replace(' ', '')\n",
    "unacc_df['image_urls'] = unacc_df['image_urls'].str.replace('.md..', '.md.')\n",
    "\n",
    "acc_list = acc_df['image_urls'].tolist()\n",
    "unacc_list = unacc_df['image_urls'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb2e1720-eaa7-42ea-a2a5-dd034d8c38e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_urls(raw_links_list):\n",
    "    url_list = []\n",
    "    bad_urls = []\n",
    "    for each in raw_links_list:\n",
    "        try:\n",
    "            headers = {'user-agent': 'ds6050 (vkb6bn@virginia.edu)'}\n",
    "            results = requests.get(each, headers=headers, timeout=2.0)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            #print('Bad URL: ' + each)\n",
    "            bad_urls.append(each)\n",
    "            continue\n",
    "        #print(results)\n",
    "        #print(each) \n",
    "        if results.status_code == 200:\n",
    "            url_list.append(each)\n",
    "    return url_list, bad_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0361bec7-d971-43a4-8151-6b93f599b74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_img_urls, acc_img_bad = sort_urls(acc_list)\n",
    "unacc_img_urls, unacc_img_bad = sort_urls(unacc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705c3087-6e9c-456f-802d-46f2d9ed5156",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    os.mkdir('images')\n",
    "    os.chdir('images')\n",
    "    \n",
    "    os.mkdir('accredited')\n",
    "    os.chdir('accredited')\n",
    "\n",
    "    path = os.getcwd()\n",
    "    parent = os.path.dirname(path)\n",
    "    new_path = os.chdir(parent)\n",
    "    # print(new_path)\n",
    "    \n",
    "    os.mkdir('unaccredited')\n",
    "    print('Directory created')\n",
    "    \n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd84683-de87-499f-b7b3-c89043b1f8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_path = './accredited/'\n",
    "unacc_path = './unaccredited/' \n",
    "\n",
    "os.getcwd()\n",
    "# make sure path opens the accredited folder, change if needed\n",
    "os.chdir(acc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8c676e-c5cc-405b-afab-c2101bd3db2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(images):\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context # bypasses SSL errors\n",
    "    icount=1\n",
    "    for each in images:\n",
    "        try:\n",
    "            if each.endswith('.jpg'):\n",
    "                urllib.request.urlretrieve(each, f'pic_{str(icount)}.jpg')\n",
    "            icount += 1\n",
    "            if each.endswith('.png'):\n",
    "                urllib.request.urlretrieve(each, f'pic_{str(icount)}.png')\n",
    "            icount += 1\n",
    "        except urllib.error.HTTPError as he:\n",
    "           # print(he.code)\n",
    "            continue\n",
    "        except urllib.error.SSLCertVerificationError as ue:\n",
    "           # print(ue.code)\n",
    "            continue\n",
    "    return icount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1bb825-2723-44df-a741-c29cf31a22d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_images(acc_img_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a379e5c6-8f44-4818-8b64-47ffacb11a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "parent = os.path.dirname(path)\n",
    "new_path = os.chdir(parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c7cb89-751d-485e-8b54-0a8c793bb4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path\n",
    "os.chdir(unacc_path)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03ee289-becc-462f-88f8-63e749473af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_images(unacc_img_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1d86a1-0e2e-40cb-859e-c6b1937cd822",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e179ef2-4102-443b-8fb3-06828d1b78c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a75807-d9ba-45fc-8e7a-934d902b0d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/sfs/qumulo/qhome/fdf7gn/images/')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28243f6f-4974-4e97-a1b2-7ff3a62e7434",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitfolders.ratio('/sfs/qumulo/qhome/fdf7gn/images', output=\"split\", seed=123, ratio=(.8, 0.1,0.1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaef7bc3-f61b-46a5-a580-f54959b61660",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['accredited', 'unaccredited']\n",
    "img_size = 224\n",
    "def get_data(data_dir):\n",
    "    data = [] \n",
    "    for label in labels: \n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(path, img))[...,::-1] #convert BGR to RGB format\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n",
    "                data.append([resized_arr, class_num])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b1deb3-cdee-4863-95ff-ce3657eddf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = get_data('/sfs/qumulo/qhome/fdf7gn/images/split/train')\n",
    "val = get_data('/sfs/qumulo/qhome/fdf7gn/images/split/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25e1ddb-bc8c-42cc-b9ba-1e9c3bfa46a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in train:\n",
    "    if(i[1] == 0):\n",
    "        l.append(\"accredited\")\n",
    "    else:\n",
    "        l.append(\"unaccredited\")\n",
    "#sns.set_style('darkgrid')\n",
    "#sns.countplot(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04b4d65-0606-4679-a0a4-ed03dbf052d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_x_train = []\n",
    "image_y_train = []\n",
    "image_x_val = []\n",
    "image_y_val = []\n",
    "\n",
    "for feature, label in train:\n",
    "  image_x_train.append(feature)\n",
    "  image_y_train.append(label)\n",
    "\n",
    "for feature, label in val:\n",
    "  image_x_val.append(feature)\n",
    "  image_y_val.append(label)\n",
    "\n",
    "# Normalize the data\n",
    "image_x_train = np.array(image_x_train) / 255\n",
    "image_x_val = np.array(image_x_val) / 255\n",
    "\n",
    "image_x_train.reshape(-1, img_size, img_size, 1)\n",
    "image_y_train = np.array(image_y_train)\n",
    "\n",
    "image_x_val.reshape(-1, img_size, img_size, 1)\n",
    "image_y_val = np.array(image_y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b351587-ba8e-4d13-a69f-af13f851b62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(input_shape = (224, 224, 3), include_top = False, weights = \"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a373b8b9-537a-4aa6-8517-810574016c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32381666-91f0-4333-a06e-b34eb3a79af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_model = tf.keras.Sequential([base_model,\n",
    "                                 tf.keras.layers.GlobalAveragePooling2D(),\n",
    "                                 tf.keras.layers.Dropout(0.2),\n",
    "                                 tf.keras.layers.Dense(18, activation=\"softmax\")                                     \n",
    "                                ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccad58eb-c5d7-4065-bc0a-49173073219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0012\n",
    "image_model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = image_model.fit(image_x_train,image_y_train,epochs = 50 , validation_data = (image_x_val, image_y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c644646-f67d-4582-9700-5c6513695e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x=image_x_val, y=image_y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69973bb-121b-4b95-96a6-9aa582958db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_acc = model.evaluate(x=image_x_val, y=image_y_val)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c69012-aed8-453a-8186-7606abb96ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f0d02c-494f-42ec-8724-c0033077600e",
   "metadata": {},
   "source": [
    "## MultiModal Model - Text + Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a034e38a-bc14-40eb-b8c3-7f0390d3fa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense,Flatten,Conv2D\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input,Dropout,Embedding\n",
    "from tensorflow.keras.layers import Conv1D,LSTM,MaxPooling1D,concatenate\n",
    "\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras.applications import MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75c38250-ad73-477a-b47d-fd6ec4dda35b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"tf.concat\" (type TFOpLambda).\n\nShape must be at least rank 2 but is rank 1 for '{{node tf.concat/concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](Placeholder, Placeholder_1, tf.concat/concat/axis)' with input shapes: [2], [2], [] and with computed input tensors: input[2] = <1>.\n\nCall arguments received by layer \"tf.concat\" (type TFOpLambda):\n  • values=['tf.Tensor(shape=(2,), dtype=float32)', 'tf.Tensor(shape=(2,), dtype=float32)']\n  • axis=1\n  • name=concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m image_x_train , text_x_train \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m0\u001b[39m],x[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimage_x_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtext_x_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m multi_model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m      5\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m32\u001b[39m,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      6\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      7\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m128\u001b[39m,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      8\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m4\u001b[39m,activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      9\u001b[0m ])\n\u001b[0;32m     11\u001b[0m multi_model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\layers\\core\\tf_op_layer.py:119\u001b[0m, in \u001b[0;36mKerasOpDispatcher.handle\u001b[1;34m(self, op, args, kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;124;03m\"\"\"Handle the specified operation with the specified arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(x, keras_tensor\u001b[38;5;241m.\u001b[39mKerasTensor)\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten([args, kwargs])\n\u001b[0;32m    118\u001b[0m ):\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TFOpLambda(op)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNOT_SUPPORTED\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"tf.concat\" (type TFOpLambda).\n\nShape must be at least rank 2 but is rank 1 for '{{node tf.concat/concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](Placeholder, Placeholder_1, tf.concat/concat/axis)' with input shapes: [2], [2], [] and with computed input tensors: input[2] = <1>.\n\nCall arguments received by layer \"tf.concat\" (type TFOpLambda):\n  • values=['tf.Tensor(shape=(2,), dtype=float32)', 'tf.Tensor(shape=(2,), dtype=float32)']\n  • axis=1\n  • name=concat"
     ]
    }
   ],
   "source": [
    "image_x_train , text_x_train = x[0],x[1]\n",
    "x = tf.concat([image_x_train,text_x_train],1)\n",
    "\n",
    "multi_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(32,activation='relu'),\n",
    "    tf.keras.layers.Dense(64,activation='relu'),\n",
    "    tf.keras.layers.Dense(128,activation='relu'),\n",
    "    tf.keras.layers.Dense(4,activation = 'softmax'),\n",
    "])\n",
    "\n",
    "multi_model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "                    \n",
    "history = multi_model.fit(x, epochs=50)\n",
    "                    \n",
    "\n",
    "                    \n",
    "#print(x_image.shape,x_text.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c5d034-6c18-4f87-bd04-a28f82cb71e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    flatten = Flatten()\n",
    "d1 = Dense(32,activation='relu')\n",
    "d2 = Dense(64,activation='relu')\n",
    "d3 = Dense(128,activation='relu')\n",
    "d4 = Dense(4,activation = 'softmax')\n",
    "        \n",
    "\n",
    "image_x_train , text_x_train = x[0],x[1]\n",
    "image_x_train = self.flatten(image_x_train)\n",
    "text_x_train = self.flatten(text_x_train)\n",
    "#print(x_image.shape,x_text.shape)\n",
    "x = tf.concat([image_x_train,text_x_train],1)\n",
    "x = d1(x)\n",
    "x = d2(x)\n",
    "x = d3(x)\n",
    "\n",
    "d4(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
